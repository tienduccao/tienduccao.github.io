<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="//gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.41" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Spacy pretrain command &middot; Duc Cao</title>

  
  <link type="text/css" rel="stylesheet" href="https://tienduccao.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://tienduccao.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://tienduccao.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://tienduccao.github.io/css/hyde.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Duc Cao" />

  
</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://tienduccao.github.io/"><h1>Duc Cao</h1></a>
      <p class="lead">
       Welcome to my blog 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://tienduccao.github.io/">Home</a> </li>
        
      </ul>
    </nav>

    <p>&copy; Duc Cao 2019. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="post">
  <h1>Spacy pretrain command</h1>
  <time datetime=2012-03-04T00:00:00Z class="post-date">Sun, Mar 4, 2012</time>
  <p><a href="https://explosion.ai/blog/spacy-v2-1">Spacy 2.1</a> released an interesting command <em>spacy pretrain</em>.
It loads a pre-trained vectors (<a href="https://spacy.io/models/">https://spacy.io/models/</a>
and uses a CNN model to predict each word&rsquo;s pre-trained vector instead of the word itself.
They termed this technique as <em>Language Modelling with Approximate Outputs</em> (LMAO).</p>

<p>According to the creator of Spacy, this approach is especially useful when you have limited training data
for text classification and parsing task.
He used pretraining&rsquo;s output to train a text classifier on 1,000 samples and reported
a high F1-score of <a href="https://github.com/honnibal/spacy-pretrain-polyaxon#text-classification-results">87%</a>
on the test set consisting of 5,000 samples.</p>

<p>In order to get familiar with this technique, I ran a similar experiment on a new dataset.
All the code and data are available at
<a href="https://github.com/tienduccao/spacy-pretrain-polyaxon">https://github.com/tienduccao/spacy-pretrain-polyaxon</a>,
under <em>lmao-imdb-1k</em> folder.</p>

<p>Firstly you need to convert your unlabled text into <a href="https://spacy.io/api/cli#pretrain-jsonl">.jsonl format</a> using
<code>python generate_jsonl.py</code>.
You also need to download the Spacy pre-trained vector file (<code>spacy download en_vectors_web_lg</code>).
Then executing the command<code>spacy pretrain</code> to obtain the pre-trained weights.</p>

<pre><code>spacy pretrain corpus.jsonl en_vectors_web_lg weights
</code></pre>

<p>The details of this command could be found at <a href="https://spacy.io/api/cli#pretrain">https://spacy.io/api/cli#pretrain</a>.
This task took 24,5h for 832 iterations on GeForce GTX 1080.
Some pre-trained weights are stored
<a href="https://github.com/tienduccao/spacy-pretrain-polyaxon/tree/master/lmao-imdb-1k/weights">here</a>.</p>

<p>Without using the pre-trained weights (<code>python pretrain_textcat.py 96 2000</code>), I obtained an F1-score of 73.4%.</p>

<p>The next step is training a text classifier using pre-trained weights.</p>

<pre><code>python pretrain_textcat.py -t2v weights/model800.bin 96 2000
</code></pre>

<p>Now the performance increases up to <strong>85.4%</strong>.</p>

<p>Spacy text classifier is CNN model and it is sensitive to hyperparameters.
Trying different parameters of <em>pretrain_textcat.py</em> should be done in order to achieve the optimal performance.
We could also try different pre-trained vector file (word2vec, Glove, fastText) to see if it could
lead to better performance.</p>

</div>


    </main>

    
  </body>
</html>
